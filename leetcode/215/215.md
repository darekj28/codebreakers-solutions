## Motivation
This is the textbook use case for quickselect, an algorithm for finding the k largest elements in an array. The process is as follows:
* choose a `random index` in your array (search space), let's call the value at this index the `pivot value`
* partition the array to the following format: 
`[elements smaller than pivot, pivot, everything else]` 
Note that now the `pivot value` is in the position in the array if it were sorted.
* Call the position the `pivot value` is now in the `paritition index`. We compare the `partition index` to `len(array)-k` to see if the `partition value` is the kth largest value in the array. If it is, return it. Else, recursively apply quickselect to the left if your value is too big, or the right otherwise.  

# Time Complexity: `O(n^2) worst case, O(n) average case`
The space complexity is quadratic to the input in the worst case. This occurs, for instance, in a case where we are searching for the largest number in the array, but get unlucky and always select the smallest element left in our search space. 

In expectation, however, our partition index will be in the middle of the search space, leading us to cut our work in each recursive call by half. This leads our average time complexity to be n + n/2 + n/4 + ..., which converges to 2n.  

# Space Complexity: `O(1)`
The space complexity is constant to the size of the input.